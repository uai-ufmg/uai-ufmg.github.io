---
title: VESSA | Video-based Efficient Self-Supervised Adaptation
type: landing
show_breadcrumb: true

tags: ["RP-en", "articles"]

url_dataset: ''
url_project: ''

sections:
  - block: markdown
    content:
      title: VESSA | Video-based Efficient Self-Supervised Adaptation
      subtitle: '2025'
      text: <p>This study introduces a novel approach to adapt vision foundation models to new domains without annotations, leveraging only short multi-view object-centric videos. Unlike existing self-supervised strategies, VESSA carefully combines prediction head tuning, parameter-efficient adaptation, and multi-view object observations to prevent knowledge degradation and ensure robustness. Through extensive experiments, VESSA shows consistent gains across different models and datasets, demonstrating its potential for advancing visual foundation model adaptation.
    design:
      columns: '1'
---

This work introduces a novel approach to adapt vision foundation models to new domains without annotations, leveraging only short multi-view object-centric videos. Unlike existing self-supervised strategies, VESSA carefully combines prediction head tuning, parameter-efficient adaptation, and multi-view object observations to prevent knowledge degradation and ensure robustness. Through extensive experiments, VESSA shows consistent gains across different models and datasets, demonstrating its potential for advancing visual foundation model adaptation.revealed a focus on vocal and technical cues in their judgments.
